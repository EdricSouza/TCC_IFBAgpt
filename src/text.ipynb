{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import deque\n",
    "from urllib.parse import urlparse\n",
    "from selenium.webdriver import Chrome\n",
    "\n",
    "import tiktoken\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://portal.ifba.edu.br/','https://portal.ifba.edu.br/ensino/nossos-cursos/curso-tecnico/tecnicos-integrados---','https://portal.ifba.edu.br/ensino/nossos-cursos/curso-tecnico/tecnicos-integrados-proeja---','https://portal.ifba.edu.br/ensino/nossos-cursos/curso-tecnico/tecnicos-subsequentes---','https://portal.ifba.edu.br/ensino/nossos-cursos/curso-tecnico/tecnicos-concomitantes---','https://portal.ifba.edu.br/campi/escolhacampus','https://portal.ifba.edu.br/dgcom/camacari/institucional/contato','https://portal.ifba.edu.br/dgcom/camacari/administrativo/cap']\n",
    "\n",
    "domain = \"portal.ifba.edu.br\"\n",
    "\n",
    "url = \"https://portal.ifba.edu.br/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "portal.ifba.edu.br\n",
      "deque(['https://portal.ifba.edu.br/', 'https://portal.ifba.edu.br/ensino/nossos-cursos/curso-tecnico/tecnicos-integrados---', 'https://portal.ifba.edu.br/ensino/nossos-cursos/curso-tecnico/tecnicos-integrados-proeja---', 'https://portal.ifba.edu.br/ensino/nossos-cursos/curso-tecnico/tecnicos-subsequentes---', 'https://portal.ifba.edu.br/ensino/nossos-cursos/curso-tecnico/tecnicos-concomitantes---', 'https://portal.ifba.edu.br/campi/escolhacampus', 'https://portal.ifba.edu.br/dgcom/camacari/institucional/contato', 'https://portal.ifba.edu.br/dgcom/camacari/administrativo/cap'])\n",
      "Próxima url https://portal.ifba.edu.br/dgcom/camacari/administrativo/cap\n",
      "Próxima url https://portal.ifba.edu.br/dgcom/camacari/institucional/contato\n",
      "Próxima url https://portal.ifba.edu.br/campi/escolhacampus\n",
      "Próxima url https://portal.ifba.edu.br/ensino/nossos-cursos/curso-tecnico/tecnicos-concomitantes---\n",
      "Próxima url https://portal.ifba.edu.br/ensino/nossos-cursos/curso-tecnico/tecnicos-subsequentes---\n",
      "Próxima url https://portal.ifba.edu.br/ensino/nossos-cursos/curso-tecnico/tecnicos-integrados-proeja---\n",
      "Próxima url https://portal.ifba.edu.br/ensino/nossos-cursos/curso-tecnico/tecnicos-integrados---\n",
      "Próxima url https://portal.ifba.edu.br/\n"
     ]
    }
   ],
   "source": [
    "def get_text_from_url(url):\n",
    "    '''\n",
    "        Essa função recebe uma url e faz o scraping do texto da página\n",
    "        Retorna o texto da página e salva o texto em um arquivo <url>.txt\n",
    "    '''\n",
    "\n",
    "    # Analisa a URL e pega o domínio\n",
    "    local_domain = urlparse(url).netloc\n",
    "    print(local_domain)\n",
    "\n",
    "    # Fila para armazenar as urls para fazer o scraping\n",
    "    fila = deque(urls)\n",
    "    print(fila)\n",
    "\n",
    "    # Criar um diretório para armazenar os arquivos de texto\n",
    "    if not os.path.exists(\"text/\"):\n",
    "            os.mkdir(\"text/\")\n",
    "\n",
    "    if not os.path.exists(\"text/\"+local_domain+\"/\"):\n",
    "            os.mkdir(\"text/\" + local_domain + \"/\")\n",
    "\n",
    "    # Create a directory to store the csv files\n",
    "    if not os.path.exists(\"processed\"):\n",
    "            os.mkdir(\"processed\")\n",
    "\n",
    "    # Enquanto a fila não estiver vazia, continue fazendo o scraping\n",
    "    while fila:\n",
    "        # Pega a próxima URL da fila\n",
    "        url = fila.pop()\n",
    "        print(\"Próxima url\",url) # Checa próxima url\n",
    "\n",
    "        # Salva o texto da url em um arquivo <url>.txt\n",
    "        with open('text/'+local_domain+'/'+url[8:].replace(\"/\", \"_\") + \".txt\", \"w\", encoding = 'utf8') as f:\n",
    "            driver = Chrome()\n",
    "            driver.get(url)\n",
    "            page_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            text = page_soup.get_text()\n",
    "            f.write(text)\n",
    "\n",
    "        driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_newlines(serie):\n",
    "    '''\n",
    "        Essa função recebe uma série e remove as quebras de linha\n",
    "    '''\n",
    "    serie = serie.str.replace('\\n', ' ')\n",
    "    serie = serie.str.replace('\\\\n', ' ')\n",
    "    serie = serie.str.replace('  ', ' ')\n",
    "    serie = serie.str.replace('  ', ' ')\n",
    "    return serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x81 in position 846: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m domain \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Abra o arquivo e leia o texto\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m domain \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m----> 6\u001b[0m         text \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;66;03m# Omita as primeiras 20 linhas e as últimas 4 linhas e, em seguida, substitua  -, _, e #update com espaços.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m         texts\u001b[38;5;241m.\u001b[39mappend((file[\u001b[38;5;241m20\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#update\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m), text))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcharmap_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoding_table\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x81 in position 846: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "texts=[]\n",
    "# Obter todos os arquivos de texto no diretório de texto\n",
    "for file in os.listdir(\"text/\" + domain + \"/\"):\n",
    "    # Abra o arquivo e leia o texto\n",
    "    with open(\"text/\" + domain + \"/\" + file, \"r\") as f:\n",
    "        text = f.read()\n",
    "        # Omita as primeiras 20 linhas e as últimas 4 linhas e, em seguida, substitua  -, _, e #update com espaços.\n",
    "        texts.append((file[20:-4].replace('-',' ').replace('_', ' ').replace('#update',''), text))\n",
    "\n",
    "#Criar um Dataframe a partir da lista de textos\n",
    "df = pd.DataFrame(texts, columns = ['page_name', 'text'])\n",
    "\n",
    "# Defina a coluna de texto para ser o texto bruto com as novas linhas removidas\n",
    "df['text'] = df.page_name + \". \" + remove_newlines(df.text)\n",
    "df.to_csv('processed/scraped.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
